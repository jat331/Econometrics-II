{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loving-magic",
   "metadata": {},
   "source": [
    "# Final Exam\n",
    "---\n",
    "This exam is for **James**\n",
    "\n",
    "You can load in the datasets for your exam via this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "curious-wrapping",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'(file='exam_data_James.rdata')' was not found in history, as a file, url, nor in the user namespace.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3850\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[1;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[0;32m   3849\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:                                              \u001b[38;5;66;03m# User namespace\u001b[39;00m\n\u001b[1;32m-> 3850\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[0;32m   3851\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mSyntaxError\u001b[0m: invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<string>, line 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(file=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexam_data_James.rdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\code.py:359\u001b[0m, in \u001b[0;36mCodeMagics.load\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m    357\u001b[0m opts,args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_options(arg_s,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myns:r:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    358\u001b[0m search_ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts\n\u001b[1;32m--> 359\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mfind_user_code(args, search_ns\u001b[38;5;241m=\u001b[39msearch_ns)\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3852\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[1;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[0;32m   3850\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[0;32m   3851\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3852\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in history, as a file, url, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3853\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnor in the user namespace.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m target) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   3855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(codeobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   3856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codeobj\n",
      "\u001b[1;31mValueError\u001b[0m: '(file='exam_data_James.rdata')' was not found in history, as a file, url, nor in the user namespace."
     ]
    }
   ],
   "source": [
    "load(file='exam_data_James.rdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-difficulty",
   "metadata": {},
   "source": [
    "#### Datasets loaded:\n",
    "This loads in a number of datasets:\n",
    "* Soccer score data for use in question 2 : `Q2.df` and the teams for the simulation `Q2.teams`\n",
    "* Fertility data for use in question 3:  `Q3.df`\n",
    "* Fourth down data for use in question 4: `Q4.df`\n",
    "* Multinomial choice data for use in question 5: `Q5.df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-daniel",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-recovery",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Consider the function:\n",
    "$$f(x)=1+ \\exp\\left\\{\\frac{(x-1)^2}{100}\\right\\} +\\sum_{\\omega=1}^{5} \\frac{1}{\\omega} \\frac{\\exp\\left\\{\\cos(\\omega x)\\right\\}}{\\exp\\left\\{\\cos(\\omega x)\\right\\}+1}$$\n",
    "\n",
    "#### Tasks:\n",
    "1. Code a function for the above in R and use it to output the value $f(x)$ when $x=0$ and $x=5$\n",
    "2. Plot the function on the interval $[-10,10]$\n",
    "3. Find the derivative of the function $f(x)$ at $x=-3$\n",
    "4. Find all solutions to the equation $f(x)=3.3$ and illustrate these points on your graph\n",
    "5. Find the global minimizer $x^\\star$ of the function $f(x)$, again illustrate it on your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "#1.1\n",
    "```{r}\n",
    "# Define the function f(x)\n",
    "f <- function(x) {\n",
    "  term1 <- 1 + exp((x - 1)^2 / 100)\n",
    "  term2 <- sum(1 /(1:5) * exp(cos(1:5 * x)) / (exp(cos(1:5 * x)) + 1))\n",
    "  return(term1 + term2)\n",
    "}\n",
    "\n",
    "# Calculate f(x) when x = 0 and x = 5\n",
    "f_x_0 <- f(0)\n",
    "f_x_5 <- f(5)\n",
    "cat(\"f(x) when x = 0:\", f_x_0, \"\\n\")\n",
    "cat(\"f(x) when x = 5:\", f_x_5, \"\\n\")\n",
    "```\n",
    "\n",
    "#1.2\n",
    "```{r}\n",
    "# Plot the function on the interval [-10, 10]\n",
    "x <- seq(-10, 10, by = 0.1)\n",
    "y <- sapply(x, f)\n",
    "plot(x, y, type = \"l\", main = \"Plot of f(x)\", xlab = \"x\", ylab = \"f(x)\")\n",
    "```\n",
    "#1.3\n",
    "\n",
    "```{r}\n",
    "# Define a better numerical derivative function\n",
    "c.num.deriv <- function(f, x, eps ) {\n",
    "    (f(x+eps)-f(x-eps))/(2*eps)\n",
    "}\n",
    "\n",
    "# Find the derivative of the function f(x) at x = -3\n",
    "derivative_at_minus_3 <- c.num.deriv(f, x = -3, eps = 0.0001)\n",
    "cat(\"Derivative of f(x) at x = -3:\", derivative_at_minus_3, \"\\n\")\n",
    "```\n",
    "\n",
    "#1.4\n",
    "```{r}\n",
    "# Load the rootSolve package\n",
    "library(rootSolve)\n",
    "\n",
    "# Define the function f(x)\n",
    "f <- function(x) {\n",
    "  term1 <- 1 + exp((x - 1)^2 / 100)\n",
    "  term2 <- sum(1 /(1:5) * exp(cos(1:5 * x)) / (exp(cos(1:5 * x)) + 1))\n",
    "  return(term1 + term2)\n",
    "}\n",
    "\n",
    "# Define a function for f(x) - 3.3\n",
    "f_minus_3.3 <- function(x) {\n",
    "  f(x) - 3.3\n",
    "}\n",
    "\n",
    "# Find all solutions to the equation f(x) = 3.3\n",
    "roots <- uniroot.all(f_minus_3.3, interval = c(-10, 10))\n",
    "\n",
    "# Plot the function on the interval [-10, 10]\n",
    "x <- seq(-10, 10, by = 0.1)\n",
    "y <- sapply(x, f)\n",
    "plot(x, y, type = \"l\", main = \"Plot of f(x) and Solutions to f(x) = 3.3\", xlab = \"x\", ylab = \"f(x)\")\n",
    "\n",
    "# Plot the solutions on the graph\n",
    "points(roots, rep(3.3, length(roots)), col = \"red\", pch = 19)\n",
    "\n",
    "# Plot the line y = 3.3\n",
    "abline(h = 3.3, col = \"blue\")\n",
    "\n",
    "# Find the intersection points\n",
    "intersection_points <- x[which(diff(sign(y - 3.3)) != 0)]\n",
    "\n",
    "# Plot x's at the intersection points\n",
    "points(intersection_points, rep(3.3, length(intersection_points)), col = \"green\", pch = \"x\")\n",
    "\n",
    "# Print the x values at the intersection points\n",
    "cat(\"x values at the intersection points:\", intersection_points, \"\\n\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#1.5\n",
    "```{r}\n",
    "# Find the global minimizer x⋆ of the function f(x)\n",
    "library(stats)\n",
    "x_minimizer <- optimize(f, interval = c(-10, 10))$minimum\n",
    "cat(\"Global minimizer of f(x):\", x_minimizer, \"\\n\")\n",
    "\n",
    "# Plotting the function and global minimizer\n",
    "x <- seq(-10, 10, by = 0.1)\n",
    "y <- sapply(x, f)\n",
    "plot(x, y, type = \"l\", main = \"Plot of f(x)\", xlab = \"x\", ylab = \"f(x)\") + abline(h = 2.078263, col = \"red\", lty = 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-portuguese",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-healing",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Simulation Question\n",
    "\n",
    "#### Tasks:\n",
    "1. Using the data in `Q2.df` provide a scatterplot for the average number of goals scored by each team in the data.\n",
    "2. Using the soccer score data in `Q2.df` estimate a Poisson model of goal production where you allow for:\n",
    "    * An intercept\n",
    "    * A home-team effect\n",
    "    * A team specific attack term\n",
    "    * A team specific defense term\n",
    "    \n",
    "    Illustrate the estimated model with a scatter plot the expected number of goals scored and conceded for each of the twenty teams.\n",
    "\n",
    "2. After estimating the model, I want you to use the parameters in a simulation of four teams in a knockout competition. \n",
    "    * Your four teams are: A,B C,D are given below in the `Q2.teams` variable\n",
    "    * The aim is to provide the probability that each of the four team wins the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2.teams\n",
    "```{r}\n",
    "# Filter the data to include only rows where the team is under AttackTeam\n",
    "attack_data <- Q2.df[Q2.df$Home == 0, ]\n",
    "\n",
    "# Calculate the total number of goals scored by each team when they are under AttackTeam\n",
    "team_goals <- tapply(attack_data$Goals, attack_data$AttackTeam, sum)\n",
    "\n",
    "# Calculate the total number of times each team appears under AttackTeam\n",
    "team_counts <- table(attack_data$AttackTeam)\n",
    "\n",
    "# Calculate the average number of goals scored by each team\n",
    "average_goals <- team_goals / team_counts\n",
    "\n",
    "# Create a new dataframe with team names and their average goals\n",
    "team_avg_goals <- data.frame(Team = names(average_goals), AverageGoals = average_goals)\n",
    "\n",
    "# Create the bar chart\n",
    "library(ggplot2)\n",
    "ggplot(data = team_avg_goals, aes(x = Team, y = AverageGoals.Freq)) +\n",
    "  geom_bar(stat = \"identity\", fill = \"purple\") +\n",
    "  labs(x = \"Team\", y = \"Average Goals\", title = \"Average Number of Goals Scored by Each Team\")+\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 0.5))\n",
    "```\n",
    "#2.2\n",
    "\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "\n",
    "# Estimate Poisson model\n",
    "poisson_model <- glm(Goals ~ Home + as.factor(AttackTeam) + as.factor(DefendTeam), \n",
    "                     data = Q2.df, family = poisson)\n",
    "\n",
    "# Predict expected goals scored and conceded for each team\n",
    "expected_goals <- predict(poisson_model, type = \"response\", newdata = Q2.df)\n",
    "\n",
    "# Create a new dataframe with team names, expected goals scored, and expected goals conceded\n",
    "team_expected_goals <- data.frame(Team = Q2.df$AttackTeam,\n",
    "                                  ExpectedGoalsScored = expected_goals,\n",
    "                                  ExpectedGoalsConceded = expected_goals)\n",
    "\n",
    "# Aggregate by team to get average expected goals scored and conceded\n",
    "team_avg_expected_goals <- aggregate(. ~ Team, data = team_expected_goals, mean)\n",
    "\n",
    "# Create scatter plot\n",
    "ggplot(data = team_avg_expected_goals, aes(x = ExpectedGoalsScored, y = ExpectedGoalsConceded, label = Team)) +\n",
    "  geom_point(size = 3, color = \"blue\") +\n",
    "  geom_text(vjust = -0.5, hjust = 0.5) +\n",
    "  labs(x = \"Expected Goals Scored\", y = \"Expected Goals Conceded\", \n",
    "       title = \"Expected Goals Scored vs Conceded for Each Team\") +\n",
    "  theme_minimal()+\n",
    "  theme(axis.text.x = element_text(angle = 60, hjust = 1, vjust = 1))\n",
    "```\n",
    "```{r}\n",
    "# Define the teams\n",
    "Q2.teams <- c(\"A\", \"B\", \"C\", \"D\")\n",
    "\n",
    "# Function to simulate a match outcome based on Poisson model parameters\n",
    "simulate_match <- function(home_team, away_team, home_attack, home_defense, away_attack, away_defense) {\n",
    "  # Simulate goals scored by home and away teams\n",
    "  home_goals <- rpois(1, lambda = exp(home_attack + away_defense))\n",
    "  away_goals <- rpois(1, lambda = exp(away_attack + home_defense))\n",
    "  \n",
    "  # Check for missing values\n",
    "  if (is.na(home_goals) || is.na(away_goals)) {\n",
    "    return(NA)  # Return NA if any goals are missing\n",
    "  }\n",
    "  \n",
    "  # Determine the winner\n",
    "  if (home_goals > away_goals) {\n",
    "    return(home_team)\n",
    "  } else if (home_goals < away_goals) {\n",
    "    return(away_team)\n",
    "  } else {\n",
    "    # If it's a draw, simulate penalty shootout (fair coin-toss)\n",
    "    if (runif(1) > 0.5) {\n",
    "      return(home_team)\n",
    "    } else {\n",
    "      return(away_team)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Function to simulate the knockout competition\n",
    "simulate_knockout <- function(home_teams, away_teams, home_attack, home_defense, away_attack, away_defense) {\n",
    "  # Semi-final matches\n",
    "  semi_finals <- list(c(home_teams[1], away_teams[1]), c(home_teams[2], away_teams[2]))\n",
    "  \n",
    "  # Simulate semi-finals\n",
    "  semi_finals_results <- lapply(semi_finals, function(match) {\n",
    "    simulate_match(match[1], match[2], home_attack[match[1]], home_defense[match[1]], away_attack[match[2]], away_defense[match[2]])\n",
    "  })\n",
    "  \n",
    "  # Check for missing values in semi-finals results\n",
    "  if (any(is.na(semi_finals_results))) {\n",
    "    return(NA)  # Return NA if any semi-final result is missing\n",
    "  }\n",
    "  \n",
    "  # Check for draw in semi-finals\n",
    "  if (semi_finals_results[[1]] == semi_finals_results[[2]]) {\n",
    "    # Play semi-finals again with other teams at home\n",
    "    semi_finals_results <- lapply(semi_finals, function(match) {\n",
    "      simulate_match(match[2], match[1], home_attack[match[2]], home_defense[match[2]], away_attack[match[1]], away_defense[match[1]])\n",
    "    })\n",
    "  }\n",
    "  \n",
    "  # Final match\n",
    "  final_result <- simulate_match(semi_finals_results[[1]], semi_finals_results[[2]], \n",
    "                                 home_attack[semi_finals_results[[1]]], home_defense[semi_finals_results[[1]]], \n",
    "                                 away_attack[semi_finals_results[[2]]], away_defense[semi_finals_results[[2]]])\n",
    "  \n",
    "  return(final_result)\n",
    "}\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Number of simulation trials\n",
    "num_trials <- 10000\n",
    "\n",
    "# Empty vector to store tournament winners\n",
    "tournament_winners <- character(num_trials)\n",
    "\n",
    "# Run simulations\n",
    "for (i in 1:num_trials) {\n",
    "  tournament_winners[i] <- simulate_knockout(c(\"A\", \"C\"), c(\"B\", \"D\"), \n",
    "                                             poisson_model$coefficients[\"Home\"],\n",
    "                                             poisson_model$coefficients[paste0(\"as.factor(AttackTeam)\", Q2.teams)],\n",
    "                                             poisson_model$coefficients[paste0(\"as.factor(DefendTeam)\", Q2.teams)],\n",
    "                                             poisson_model$coefficients[paste0(\"as.factor(DefendTeam)\", Q2.teams)])\n",
    "}\n",
    "\n",
    "# Calculate probabilities of each team winning\n",
    "winning_probabilities <- table(tournament_winners) / num_trials\n",
    "\n",
    "# Print results\n",
    "winning_probabilities\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-rover",
   "metadata": {},
   "source": [
    "Given the estimated Poisson coefficients, I want you to estimate the probability (via a suitably sized simulation) that each team wins a knockout competition. \n",
    "* The knockout competition has a fixed format composed of: \n",
    "         * Team A plays Team B  (with A at home) \n",
    "         * Team C plays Team D  (with C at home)\n",
    "* The winners of the two semi-finals then play each other in a final game where neither has home advantage (set the variable to zero for both).\n",
    "* **In the event of a draw in the semi-final** the two teams that drew should play one another again, but with the other team (B and D) at home\n",
    "* **In the event of a draw in the final, or with two draws in a semi-finals** you should model a penalty shootout as a fair coin-toss to determine a winner with equal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-economy",
   "metadata": {},
   "source": [
    "Estimation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Q2.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-blocking",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-density",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "The `Q3.df` dataset contains data on:\n",
    "* whether a sample of married couples have children (`Has.Children`):\n",
    "* the parents education (the factor variable `par.educ`) \n",
    "* household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Q3.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-access",
   "metadata": {},
   "source": [
    "While the data here is binary, we will attempt to estimate the parameter for a poisson random variable to get the expected **number** of children. To do this I want you to estimate two logit models one to predict the `Has.Children` variable (1 or more children) and one to predict the `Two.Or.More.Children` (2 or more children) where we allow for the mean to vary with: \n",
    "* The log of household income\n",
    "* Allowing for different intercepts for the education factor variable.\n",
    "\n",
    "After this we will attempt to transform our estimates to get a *guess* for a Poisson parameter for the number of children.\n",
    "\n",
    "#### Tasks:\n",
    "1. First run a standard logit model to get a guess for the $\\beta$ parameters (how income and education affect the chances of having children). Report the estimated model.\n",
    "\n",
    "2. Using your model, estimate the probability that a couple with median income and where neither has a college education does **not** have children. \n",
    "\n",
    "3. Repeat this to estimate the probability that a couple with median income and where both parents are college educated have more than two children.\n",
    "\n",
    "4. Combine the data/logit models to provide an estimate for a college-educated couple have zero, one and two or more children.\n",
    "\n",
    "5. Using your estimated models (this can just be your answer in part 4) and assuming that the number of children (0,1,2,3,...) is distributed as a Poisson, illustrate the mean number of children that a Both.HS educated couple have as a function of their income. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "```{r}\n",
    "# Load necessary packages\n",
    "#install.packages(\"mlogit\")\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(mlogit)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Load the dataset Q3.df\n",
    "# Assuming the dataset is already loaded and named as Q3.df\n",
    "```\n",
    "\n",
    "#3.1\n",
    "```{r}\n",
    "# First, let's run the standard logit model for having children (Has.Children)\n",
    "model_has_children <- glm(Has.Children ~ log(income) + par.educ, data = Q3.df, family = binomial)\n",
    "\n",
    "# Now, let's run the logit model for having two or more children (Two.Or.More.Children)\n",
    "model_two_or_more_children <- glm(Two.Or.More.Children ~ log(income) + par.educ, data = Q3.df, family = binomial)\n",
    "\n",
    "# Display the estimated models\n",
    "summary(model_has_children)\n",
    "summary(model_two_or_more_children)\n",
    "```\n",
    "\n",
    "#3.2\n",
    "```{r}\n",
    "# Median income\n",
    "median_income <- median(Q3.df$income)\n",
    "\n",
    "# Probability of not having children for median income and neither has a college education\n",
    "prob_no_children <- 1-predict(model_has_children, newdata = data.frame(income = median_income, par.educ = \"both.hs\"), type = \"response\")\n",
    "prob_no_children\n",
    "```\n",
    "\n",
    "#3.3\n",
    "\n",
    "```{r}\n",
    "# Probability of having more than two children for median income and both parents college educated\n",
    "prob_more_than_two_children <- predict(model_two_or_more_children, newdata = data.frame(income = median_income, par.educ = \"both.college\"), type = \"response\")\n",
    "prob_more_than_two_children\n",
    "```\n",
    "\n",
    "#3.4\n",
    "```{r}\n",
    "# Probability of having zero, one, and two or more children for college-educated couple\n",
    "prob_zero_children <- predict(model_has_children, newdata = data.frame(income = median_income, par.educ = \"both.college\"), type = \"response\")\n",
    "prob_one_child <- 1 + prob_no_children - prob_zero_children\n",
    "prob_two_or_more_children <- prob_more_than_two_children\n",
    "\n",
    "# Display probabilities\n",
    "prob_zero_children\n",
    "prob_one_child\n",
    "prob_two_or_more_children\n",
    "```\n",
    "#3.5\n",
    "```{r}\n",
    "# Generate income values for illustration\n",
    "income_values <- seq(min(Q3.df$income), max(Q3.df$income), length.out = 100)\n",
    "\n",
    "# Predict mean number of children for Both.HS educated couple as a function of income\n",
    "mean_children <- exp(predict(model_has_children, newdata = data.frame(income = income_values, par.educ = \"both.hs\"), type = \"link\"))\n",
    "\n",
    "# Plot mean number of children as a function of income\n",
    "plot(income_values, mean_children, type = \"l\", xlab = \"Household Income\", ylab = \"Mean Number of Children\", main = \"Mean Number of Children for Both.HS Educated Couple vs. Income\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-drama",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-variance",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "The `Q4.df` dataset contains data on fourth-down conversion in the NFL over the past twelve years. The dataset includes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Q4.df)\n",
    "#4.1\n",
    "```{r}\n",
    "# Calculate the count and percentage of successful conversions for each distance to convert\n",
    "conversion_count <- tapply(Q4.df$converted, Q4.df$yds.conver, sum)\n",
    "conversion_percent <- conversion_count / table(Q4.df$yds.conver) * 100\n",
    "\n",
    "# Define color scale based on frequency\n",
    "color_scale <- rev(heat.colors(length(conversion_percent)))\n",
    "\n",
    "# Plotting the bar plot with colored bars\n",
    "barplot(conversion_percent, \n",
    "        ylim = c(0, 100), \n",
    "        col = color_scale, \n",
    "        xlab = \"Distance to Convert (yards)\", \n",
    "        ylab = \"Percentage of Conversions (%)\", \n",
    "        main = \"Conversion Frequency by Distance\")\n",
    "\n",
    "# Adding grid lines\n",
    "grid()\n",
    "\n",
    "# Adding count labels\n",
    "text(x = barplot(conversion_percent, plot = FALSE), y = conversion_percent + 2, labels = conversion_count, col = \"white\", pos = 3)\n",
    "#Red means infrequent, white means more frequent \n",
    "```\n",
    "\n",
    "#4.2\n",
    "\n",
    "```{r}\n",
    "# Loading the necessary package\n",
    "library(\"MASS\")\n",
    "\n",
    "# Fitting the probit regression model\n",
    "probit_model <- glm(converted ~ yds.conver + yds.goal, data = Q4.df, family = binomial(link = \"probit\"))\n",
    "\n",
    "# Printing the summary of the model\n",
    "summary(probit_model)\n",
    "```\n",
    "#4.3\n",
    "\n",
    "#4.4 Using just the data you are given, construct an alternative model/predictor that has a better fit to the data (fixing the probit estimation method)\n",
    "\n",
    "```{r}\n",
    "# Fitting logistic regression model with interaction terms\n",
    "logistic_model <- glm(converted ~ yds.conver * yds.goal, data = Q4.df, family = binomial(link = \"logit\"))\n",
    "\n",
    "# Printing the summary of the model\n",
    "summary(logistic_model)\n",
    "```\n",
    "#4.5 Using your fitted model, generate a visualization that provides an easy guide for understanding how likely the conversion attempt will be using your model.\n",
    "\n",
    "```{r}\n",
    "# Generate predicted probabilities using the logistic regression model\n",
    "predicted_probabilities <- predict(logistic_model, type = \"response\", newdata = Q4.df)\n",
    "\n",
    "# Create a dataframe with distance to convert, current yardline, and predicted probabilities\n",
    "predictions_df <- data.frame(\n",
    "  yds.conver = Q4.df$yds.conver,\n",
    "  yds.goal = Q4.df$yds.goal,\n",
    "  predicted_probability = predicted_probabilities\n",
    ")\n",
    "\n",
    "# Plotting the predicted probabilities\n",
    "library(\"ggplot2\")\n",
    "ggplot(predictions_df, aes(x = yds.conver, y = yds.goal, fill = predicted_probability)) +\n",
    "  geom_tile() +\n",
    "  scale_fill_gradient(low = \"red\", high = \"green\", name = \"Predicted Probability\") +\n",
    "  labs(x = \"Distance to Convert (yards)\", y = \"Current Yardline\", title = \"Predicted Probability of Conversion\") +\n",
    "  theme_minimal()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-homework",
   "metadata": {},
   "source": [
    "* Whether the fourth down was `converted`\n",
    "* The required distance to go to convert the down `yds.conver` (Fourth and **six**, say, would be 6)\n",
    "* The distance from the goal line `yds.goal` (so if you were on the 30-yard line this would be 30)\n",
    "\n",
    "#### Tasks:\n",
    "1. Provide a visualization for how frequently kick are converted from different distances.\n",
    "2. Estimate a probit regression model for the success of the conversion attempt using the distance to convert and the current yardline as predictors.\n",
    "3. Provide a statistical interpretation of the paramters. If possible express the effects in an intuitive way.\n",
    "4. Using just the data you are given, construct an alternative model/predictor that has a better fit to the data (fixing the probit estimation method) \n",
    "5. Using your fitted model, generate a visualization that provides an easy guide for understanding how likely the conversion attempt will be using your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-sierra",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-insight",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-click",
   "metadata": {},
   "source": [
    "The `Q5.df` dataset contains choices from 1000 individuals over four outcomes\n",
    "* Not purchasing anything in the category\n",
    "* Purchasing brand A\n",
    "* Purchasing brand B\n",
    "* Purchasing brand C\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Q5.df,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-grain",
   "metadata": {},
   "source": [
    "#### Tasks:\n",
    "1. Set up and run a standard multinomial logit where you are allowing for:\n",
    "    * a common response to price\n",
    "    * outcome specific effects over income and sex\n",
    "    After running the model report on the likelihood of a sale for each product if they were equally priced at  \\\\$30 for a male customer with \\\\$ 100,000 in income \n",
    "\n",
    "2. Run a mixed logit model with the same model as above, but where you allow the price response to be a random coefficient with a normal distribution. \n",
    "    *  Determine whether the model better fits the data\n",
    "    \n",
    "3. Using the best fitting model from the above, and the current data, construct the current market shares for each of the brands. In comparison to this, construct a counterfactual where *Brand A* lowers their prices by \\\\$2.50. What happens to the three market shares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "```{r}\n",
    "# Load necessary libraries\n",
    "library(mlogit)\n",
    "```\n",
    "\n",
    "\n",
    "#5.1\n",
    "\n",
    "```{r}\n",
    "S <- dfidx(Q5.df, idx = c(\"id\", \"option\"))\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Define the model formula\n",
    "formula <- Choice ~ price | sex + income\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Run the multinomial logit model\n",
    "mlogit.est <- mlogit(formula, S)\n",
    "```\n",
    "\n",
    "\n",
    "```{r}\n",
    "# Summarize the results\n",
    "summary(mlogit.est)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# Create a data frame with the hypothetical scenario\n",
    "hypothetical_data <- data.frame(\n",
    "  price = rep(30, nrow(S)),  # Price set to $30 for all choices\n",
    "  sex = \"male\",              # Male customer\n",
    "  income = 100000            # Income $100,000\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#5.2\n",
    "\n",
    "```{r}\n",
    "\n",
    "# Run the mixed logit model with the specified distribution for the random coefficients\n",
    "mixed_mlogit.est <- mlogit(Choice ~ price | sex + income, data = S, rpar = list(price = \"n\"))\n",
    "\n",
    "# Summarize the results\n",
    "summary(mixed_mlogit.est)\n",
    "```\n",
    "\n",
    "\n",
    "```{r}\n",
    "# Compare AIC values\n",
    "aic_standard <- AIC(mlogit.est)\n",
    "aic_mixed <- AIC(mixed_mlogit.est)\n",
    "\n",
    "# Print AIC values\n",
    "cat(\"AIC for Standard Multinomial Logit Model:\", aic_standard, \"\\n\")\n",
    "cat(\"AIC for Mixed Logit Model:\", aic_mixed, \"\\n\")\n",
    "\n",
    "# Determine which model has lower AIC\n",
    "if (aic_standard < aic_mixed) {\n",
    "  cat(\"Standard Multinomial Logit Model has a better fit according to AIC.\\n\")\n",
    "} else if (aic_standard > aic_mixed) {\n",
    "  cat(\"Mixed Logit Model has a better fit according to AIC.\\n\")\n",
    "} else {\n",
    "  cat(\"Both models have the same AIC value.\\n\")\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#5.3\n",
    "\n",
    "```{r}\n",
    "# Predict market shares using the mixed logit model\n",
    "market_shares <- predict(mixed_mlogit.est, newdata = S, type = \"prob\")\n",
    "\n",
    "# Get the number of brands (assuming number of unique choices in 'Choice' variable)\n",
    "n_brands <- ncol(market_shares)\n",
    "\n",
    "# Loop through brands and summarize market shares\n",
    "for (i in 1:n_brands) {\n",
    "  brand_name <- colnames(market_shares)[i]  # Get brand name from column name\n",
    "  market_share <- mean(market_shares[, i])  # Calculate average probability\n",
    "  cat(paste(\"Market Share for\", brand_name, \":\", round(market_share * 100, 2), \"%\", sep = \" \"))\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```{r}\n",
    "# Define the price reduction for Brand A\n",
    "price_reduction <- 2.5\n",
    "\n",
    "# Create a copy of the original data for the counterfactual scenario\n",
    "counterfactual_data <- S\n",
    "\n",
    "# Modify the price for Brand A (assuming the first option is Brand A)\n",
    "counterfactual_data$price[counterfactual_data$Choice == 1] <- \n",
    "  counterfactual_data$price[counterfactual_data$Choice == 1] - price_reduction\n",
    "\n",
    "# Predict market shares under the counterfactual scenario\n",
    "counterfactual_shares <- predict(mixed_mlogit.est, newdata = counterfactual_data, type = \"prob\")\n",
    "\n",
    "# Calculate the difference in market shares for each brand\n",
    "market_share_diff <- counterfactual_shares - market_shares\n",
    "\n",
    "# Loop through brands and print the change in market share\n",
    "for (i in 1:n_brands) {\n",
    "  brand_name <- colnames(market_shares)[i]\n",
    "  diff <- round(mean(market_share_diff[, i]) * 100, 2)  # Calculate average difference\n",
    "  cat(paste(\"Change in Market Share for\", brand_name, \":\", diff, \"%\", sep = \" \"))\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
